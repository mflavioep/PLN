{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler um arquivo texto e atribuir o texto em uma variável\n",
    "\n",
    "def ler(arq_texto):\n",
    "    arquivo = open(arq_texto, 'r', encoding='utf-8')\n",
    "    texto = arquivo.read()\n",
    "    arquivo.close()\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219702\n"
     ]
    }
   ],
   "source": [
    "texto = ler('Corpora\\\\Ubirajara.txt') #Atenção a barra dupla para abertura do arquivo\n",
    "print(len(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concordanciador\n",
    "Os concordanciadores são programas que buscam por expressões em um corpus e criam listagens dos resultados, incluindo um número determinado de outras expressões antes e depois daquela que é buscada, a fim de situá-la em um contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCORDANCIADOR simples\n",
    "\n",
    "def concordanciador(alvo, texto):\n",
    "    texto = texto.replace('\\n', ' ')\n",
    "    texto = texto.replace('\\t', ' ')\n",
    "\n",
    "    ocorrencias = list()\n",
    "    resultado = texto.find(alvo, 0)\n",
    "    while resultado > 0:\n",
    "        pos_inicial = resultado - (40 -len(alvo) // 2)\n",
    "        ocorrencias.append(texto[pos_inicial : pos_inicial + 80])\n",
    "        resultado = texto.find(alvo, resultado + 1)\n",
    "\n",
    "    return ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e, Jaguarê não te quer matar como a serpente que ataca o descuidado caçador. Dez\n",
      "reiro invencivel que tem por arma a serpente. Reconhece o teu vencedor, Pojucan,\n",
      "zes ella escapou-lhe da mão, como a serpente das garras do gavião.  «Mais uma ve\n",
      "reiro terrivel que tem por arma uma serpente.»         *       *       *       *\n",
      "«Agora eu queria ter no coração uma serpente para morder aquella que me roubou o\n",
      " porque elle tem os olhos da grande serpente de fogo, que vôa como o raio de Tup\n",
      "uerreiros ferozes, filhos da grande serpente do mar.  Um dia esses guerreiros sa\n",
      "la, muito cheiroza, a qual a grande serpente creava no bucho.  Os Tupinambás faz\n",
      " na tromba. Elle fujia, esticando a serpente; e a serpente encolhendo-se o arras\n",
      "le fujia, esticando a serpente; e a serpente encolhendo-se o arrastava até á bei\n",
      " pelo meio.  O velho tapir rompeu a serpente como se rompe uma corda de piassaba\n",
      " a liberdade. Ella tem a astucia da serpente e seu veneno.  --Eu era a cobra d'a\n",
      "to.  Vem depois Arariboia, a grande serpente das lagôas; Cauatá, o corredor das \n",
      "uas pontas girou em sua mão, como a serpente que se enrosca nos ares silvando.  \n",
      "iro invencivel que tem por arma uma serpente.  «Eu sou Ubirajara, o senhor das n\n"
     ]
    }
   ],
   "source": [
    "resultados = concordanciador('serpente', texto)\n",
    "for i in resultados:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problemas de pontuação e caracteres maiúsculos\n",
    "\n",
    "def limpar(lista):\n",
    "    lixo = '.,:;?!\"`()[]{}\\/|#$%^&*'\n",
    "    return[X.strip(lixo).lower() for X in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'maça', 'abaca.te', 'melancia']\n"
     ]
    }
   ],
   "source": [
    "corpus_sujo = ['banana', 'maça.', 'abaca.te', ':MeLancia' ]\n",
    "print(limpar(corpus_sujo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problemas de pontuação e caracteres maiúsculos\n",
    "# Inclusão do isalpha\n",
    "\n",
    "def limpar(lista):\n",
    "    lixo = '.,:;?!\"`()[]{}\\/|#$%^&*'\n",
    "    passo1 = [X.strip(lixo).lower() for X in lista]    \n",
    "    return[X for X in passo1 if X.isalpha() or '-' in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'maça', 'melancia', 'busca-se']\n"
     ]
    }
   ],
   "source": [
    "corpus_sujo = ['banana', 'maça.', 'abaca.te', ':MeLancia', 'busca-se' ]\n",
    "print(limpar(corpus_sujo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpando o corpus\n",
    "len(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras = limpar(palavras)\n",
    "len(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulário e riqueza lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6944"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análises quantitativas\n",
    "# Estabelecimento do vocabulário do corpus, as palavras não podem ser repetidas\n",
    "\n",
    "vocabulario = set(palavras)\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1928835310130274\n"
     ]
    }
   ],
   "source": [
    "# Cálculo da riqueza lexical\n",
    "\n",
    "riqueza = len(vocabulario) / len(palavras)\n",
    "print(riqueza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de palavras por ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocorrencias(lista_palavras):\n",
    "    dicionario = defaultdict(int)\n",
    "    for p in lista_palavras:\n",
    "        dicionario[p] += 1\n",
    "    return dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \t 1473\n",
      "o \t 1378\n",
      "de \t 1199\n",
      "que \t 1118\n",
      "e \t 918\n",
      "do \t 685\n",
      "da \t 624\n",
      "os \t 490\n",
      "para \t 346\n",
      "não \t 335\n"
     ]
    }
   ],
   "source": [
    "dic = ocorrencias(palavras)\n",
    "mf = sorted(dic.items(), key=lambda tupla:tupla[1], reverse=True) [:10] # [:10] lista as 10 ocorrencias\n",
    "for palavra, n in mf:\n",
    "    print(palavra,'\\t',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe que as palavras de maior ocorrência são as palavras funcionais, isto é, \n",
    "# palavras de reduzida contribuição semântica ou nocional, que servem apenas para\n",
    "# estabelecer relações de outras palavras entre si.\n",
    "# \n",
    "# Pela fraca contribuição semântica é comum que estas palavras sejam eliminadas \n",
    "# do CORPUS nas análises computacionais relacionadas ao significado.\n",
    "# São tidas como \"palavra vazia\" (stop words), que também podem incluir substantivos e verbos banais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mflav\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "vazias = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O resultado deve ser 0, ou seja, todas as dez palavras mais frequentes do livro são vazias\n",
    "frequentes_plenas = [X for X in mf if X[0].lower() not in vazias]\n",
    "len(frequentes_plenas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \t 1473\n",
      "o \t 1378\n",
      "de \t 1199\n",
      "que \t 1118\n",
      "e \t 918\n",
      "do \t 685\n",
      "da \t 624\n",
      "os \t 490\n",
      "para \t 346\n",
      "não \t 335\n",
      "dos \t 327\n",
      "se \t 290\n",
      "as \t 265\n",
      "como \t 243\n",
      "guerreiro \t 235\n",
      "um \t 229\n",
      "seu \t 215\n",
      "em \t 212\n",
      "na \t 205\n",
      "mais \t 205\n"
     ]
    }
   ],
   "source": [
    "mf = sorted(dic.items(), key=lambda tupla:tupla[1], reverse=True) [:20] # [:20] lista as 10 ocorrencias\n",
    "for palavra, n in mf:\n",
    "    print(palavra,'\\t',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O resultado deve ser 1, a palavra guerreiro não é uma palavra vazia\n",
    "frequentes_plenas = [X for X in mf if X[0].lower() not in vazias]\n",
    "len(frequentes_plenas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hápax legômena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hápax legômena, no plural, ou Hápax legômenon, no singular, é o termo técnico usado\n",
    "# para designar as palavras com única ocorrência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapax = [X for X in palavras if palavras.count(X) == 1]\n",
    "len(hapax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um dos problemas à identificar são as formas raras de conjugação verbal, assim reduz-se\n",
    "# todas as palavras do corpus as sua raízes morfológicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\mflav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O stemmer do NLTK reduz as palavras as suas raízes\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "raizes = [stemmer.stem(X) for X in set(palavras)]\n",
    "hapax = [X for X in raizes if raizes.count(X) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6944 \t 3210\n"
     ]
    }
   ],
   "source": [
    "print(len(raizes),'\\t',len(hapax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acompanh', 'abrig', 'poderoz', 'assez', 'burac', 'dê', 'ubiraj', 'recolh', 'am', 'transport', 'noiv', 'desmentir', 'pul', 'trabalh', 'following', 'ici', 'fórmul', 'através', 'receb', 'crav', 'var', 'aparec', 'mat', 'dezign', 'arc', 'manuel', 'nunci', 'nobr', 'torn', 'cit'] \n",
      " ['assez', 'burac', 'transport', 'desmentir', 'pul', 'following', 'ici', 'fórmul', 'através', 'manuel', 'nunci', 'god', 'sul', 'contributiom', 'c', 'orbigny', 'avilt', 'corisc', 'influenc', '420:--«luct', 'glor', 'whenev', 'iii', 'quibu', 'aflij', 'gravid', 'advenit', 'numb', 'intoleranc', 'conjur']\n"
     ]
    }
   ],
   "source": [
    "print(raizes[:30],'\\n',hapax[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247119815668203\n"
     ]
    }
   ],
   "source": [
    "# Uma outra medida de riqueza lexical do corpus seria dada pela divisão do conjunto\n",
    "# de raízes distintas pela contagem absoluta de ocorrências de raízes, ou seja, \n",
    "# divisão de types por tokens\n",
    "\n",
    "print(len(set(raizes)) / len(raizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatística Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência absoluta: número de observações de determinada variável, como o número de caracteres por exemplo.\n",
    "# Frequência relativa: proporção de determinadas observações dividida pelo total de observações, como no caso\n",
    "#                      caso da riqueza lexical.\n",
    "#\n",
    "# A estatística descritiva tem como objetivo organizar dados na forma de sínteses quantitativas e medidas \n",
    "# comparativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import machado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machado de Assis -- Obra Completa\n",
      "\n",
      "http://machado.mec.gov.br/\n",
      "\n",
      "Public Domain\n",
      "\n",
      "Contents:\n",
      "\n",
      "Romance\n",
      "\n",
      "romance/marm01.txt: Ressurreição (1872)\n",
      "romance/marm02.txt: A Mão e a Luva (1874)\n",
      "romance/marm03.txt: Helena (1876)\n",
      "romance/marm04.txt: Iaiá Garcia (1878)\n",
      "romance/marm05.txt: Memórias Póstumas de Brás Cubas (1881)\n",
      "romance/marm06.txt: Casa Velha (1885)\n",
      "romance/marm07.txt: Quincas Borba (1891)\n",
      "romance/marm08.txt: Dom Casmurro (1899)\n",
      "romance/marm09.txt: Esaú e Jacó (1904)\n",
      "romance/marm10.txt: Memorial de Aires (1908)\n",
      "\n",
      "Poesia\n",
      "\n",
      "poesia/maps01.txt: Crisálidas (1864)\n",
      "poesia/maps02.txt: Falenas (1870)\n",
      "poesia/maps03.txt: Americanas (1875)\n",
      "poesia/maps04.txt: Gazeta de Holanda (1886-88)\n",
      "poesia/maps05.txt: Ocidentais (1901)\n",
      "poesia/maps06.txt: O Almada (1908)\n",
      "poesia/maps07.txt: Dispersas (1854-1939)\n",
      "\n",
      "Contos\n",
      "\n",
      "contos/macn001.txt: Contos Fluminenses (1870); Miss Dollar; Luís Soares; A mulher de preto; O segredo de Augusta; Confissões de uma viúva moça; Linha reta e linha curva; Frei Sim\n",
      "contos/macn002.txt: Histórias da meia-noite (1873); A parasita azul; As bodas de Luís Duarte; Ernesto de Tal; Aurora sem dia; O relógio de ouro; Ponto de vista\n",
      "contos/macn003.txt: Papéis avulsos (1882); O alienista; Teoria do medalhão; A chinela turca; Na arca; D. Benedita; O segredo do bonzo; O anel de Polícrates; O empréstimo; A sereníssima república; O espelho; Uma visita de Alcibíades; Verba testamentária\n",
      "contos/macn004.txt: Histórias sem data (1884); A igreja do Diabo; O lapso; Último capítulo; Cantiga de esponsais; Singular ocorrência; Galeria póstuma; Capítulo dos chapéus; Conto alexandrino; Rimas de Sapucaia!; Uma senhora; Anedota pecuniária; Fulano; A segunda vida; Noite de almirante; Manuscrito de um sacristão; Ex cathedra; A senhora do Galvão; As academias de Sião\n",
      "contos/macn005.txt: Várias histórias (1896); A cartomante; Entre santos; Uns braços; Um homem célebre; A desejada das gentes; A causa secreta; Trio em lá menor; Adão e Eva; O enfermeiro; O diplomático; Mariana; Conto de escola; Um apólogo; D. Paula; Viver!; O cônego ou Metafísica do estilo\n",
      "contos/macn006.txt: Páginas recolhidas (1899); O caso da vara; O dicionário; Um erradio; Eterno!; Missa do galo; Idéias de canário; Lágrimas de Xerxes; Papéis velhos\n",
      "contos/macn007.txt: Relíquias de Casa Velha (1906); Pai contra mãe; Maria Cora; Marcha fúnebre; Um capitão de voluntários; Suje-se gordo!; Umas férias; Evolução; Pílades e Orestes; Anedota do cabriolet\n",
      "\n",
      "Traducao\n",
      "\n",
      "traducao/matr01.txt: Suplício de uma mulher (1865)\n",
      "traducao/matr02.txt: Os trabalhadores do mar (1866)\n",
      "traducao/matr03.txt: Oliver Twist (1870)\n",
      "\n",
      "Teatro\n",
      "\n",
      "teatro/matt01.txt: As forcas caudinas (1956)\n",
      "teatro/matt02.txt: Hoje avental, amanhã luva (1860)\n",
      "teatro/matt03.txt: Desencantos (1861)\n",
      "teatro/matt04.txt: O caminho da porta / O protocolo (1863)\n",
      "teatro/matt05.txt: Quase ministro (1864)\n",
      "teatro/matt06.txt: Os deuses de casaca (1866)\n",
      "teatro/matt07.txt: O bote de rapé (1878)\n",
      "teatro/matt08.txt: Tu, só tu, puro amor (1880)\n",
      "teatro/matt09.txt: Não consultes médico (1899)\n",
      "teatro/matt10.txt: Lição de botânica (1906)\n",
      "\n",
      "Cronica\n",
      "\n",
      "cronica/macr01.txt: Comentários da semana (1861-1863)\n",
      "cronica/macr02.txt: Crônicas do Dr. Semana (1861-1864)\n",
      "cronica/macr03.txt: Crônicas - O futuro (1862-1863)\n",
      "cronica/macr04.txt: Ao acaso (1864-1865)\n",
      "cronica/macr05.txt: Cartas fluminenses (1867)\n",
      "cronica/macr06.txt: Badaladas (1871-1873)\n",
      "cronica/macr07.txt: História de quinze dias (1876-1877)\n",
      "cronica/macr08.txt: História dos trinta dias (1878)\n",
      "cronica/macr09.txt: Notas semanais (1878)\n",
      "cronica/macr10.txt: Balas de estalo (1883-1886)\n",
      "cronica/macr11.txt: Bons dias! (1888-1889)\n",
      "cronica/macr12.txt: A semana (1892-1800)\n",
      "cronica/macr13.txt: O jornal e o livro (1859)\n",
      "cronica/macr14.txt: A reforma pelo jornal (1859)\n",
      "cronica/macr15.txt: Aquarelas (1859)\n",
      "cronica/macr16.txt: O Visconde de Castilho (1875)\n",
      "cronica/macr17.txt: Cherchez la femme (1881)\n",
      "cronica/macr18.txt: José de Alencar (1883)\n",
      "cronica/macr19.txt: Joaquim Serra (1888)\n",
      "cronica/macr20.txt: O futuro dos argentinos (1888)\n",
      "cronica/macr21.txt: Entre 1892 e 1894 (1892-1894)\n",
      "cronica/macr22.txt: Henrique Chaves (1893)\n",
      "cronica/macr23.txt: Henrique Lombaerts (1897)\n",
      "cronica/macr24.txt: O velho Senado (1898)\n",
      "critica/mact01.txt: O Passado, o presente e o futuro da literatura (1858)\n",
      "critica/mact02.txt: Idéias sobre o teatro (1859)\n",
      "critica/mact03.txt: Revista dos teatros (1859)\n",
      "critica/mact04.txt: Revista Dramática (1860)\n",
      "critica/mact05.txt: A Crítica teatral. José de Alencar: Mãe (1860)\n",
      "critica/mact06.txt: Crítica variada - Diário do RJ (1862)\n",
      "critica/mact07.txt: Flores e Frutos, de Bruno Seabra (1862)\n",
      "critica/mact08.txt: Pareceres - Conservatório Dramático (1862-1864)\n",
      "critica/mact09.txt: Homem de Mello e B. Pinheiro  A Constituinte perante a História e Sombras e Luz (1863)\n",
      "critica/mact10.txt: Peregrinação pela província de S. Paulo , por A. E. Zaluar (1863)\n",
      "critica/mact11.txt: Revelações , de A. E. Zaluar (1863)\n",
      "critica/mact12.txt: Dois folhetins. Suplício de uma mulher (1865)\n",
      "critica/mact13.txt: O Ideal do crítico (1865)\n",
      "critica/mact14.txt: Álvares de Azevedo: Lira dos vinte anos (1866)\n",
      "critica/mact15.txt: Crítica teatral (1866)\n",
      "critica/mact16.txt: Fagundes Varela  Cantos e fantasias (1866)\n",
      "critica/mact17.txt: J .M. de Macedo: O culto do dever (1866)\n",
      "critica/mact18.txt: José de Alencar: Iracema (1866)\n",
      "critica/mact19.txt: Junqueira Freire: Inspirações do claustro (1866)\n",
      "critica/mact20.txt: Porto Alegre: Colombo (1866)\n",
      "critica/mact21.txt: Propósito (1866)\n",
      "critica/mact22.txt: Castro Alves (1868)\n",
      "critica/mact23.txt: Lúcio de Mendonça: Névoas matutinas (1872)\n",
      "critica/mact24.txt: Un cuento endemoniado e La mujer misteriosa , de Guilherme Malta (1872)\n",
      "critica/mact25.txt: Notícia da atual literatura brasileira: Instinto de nacionalidade (1873)\n",
      "critica/mact26.txt: Fagundes Varela (1875)\n",
      "critica/mact27.txt: Eça de Queirós: O primo Basílio (1878)\n",
      "critica/mact28.txt: Francisco de Castro: Harmonias errantes (1878)\n",
      "critica/mact29.txt: A Nova geração (1879)\n",
      "critica/mact30.txt: Carlos Jansen: Contos seletos das mil e uma noites (1882)\n",
      "critica/mact31.txt: Raimundo Correia: Sinfonias (1882)\n",
      "critica/mact32.txt: Alberto de Oliveira: Meridionais (1884)\n",
      "critica/mact33.txt: Enéias Galvão: Miragens (1885)\n",
      "critica/mact34.txt: L. L. Fernandes Pinheiro Júnior: Tipos e quadros (1886)\n",
      "critica/mact35.txt: José de Alencar: O Guarani (1887)\n",
      "critica/mact36.txt: Henriqueta Renan (1896)\n",
      "critica/mact37.txt: Discursos na Academia Brasileira de Letras (1897)\n",
      "critica/mact38.txt: Magalhães de Azeredo: Procelárias (1898)\n",
      "critica/mact39.txt: Cenas da vida amazônica , de José Veríssimo (1899)\n",
      "critica/mact40.txt: Garrett (1899)\n",
      "critica/mact41.txt: Eça de Queirós (1900)\n",
      "critica/mact42.txt: Eduardo Prado (1901)\n",
      "critica/mact43.txt: Magalhães de Azeredo e Mário de Alencar: Horas sagradas e Versos (1902)\n",
      "critica/mact44.txt: Oliveira Lima: Secretário d'el-rei (1904)\n",
      "critica/mact45.txt: Joaquim Nabuco: Pensées détachées et souvenirs (1906)\n",
      "\n",
      "Miscelanea\n",
      "\n",
      "miscelanea/mams01.txt: Os imortais (1859)\n",
      "miscelanea/mams02.txt: Queda que as mulheres têm para os tolos (1861)\n",
      "miscelanea/mams03.txt: Carta ao Sr. Bispo do RJ (1862)\n",
      "miscelanea/mams04.txt: Carta à redação da Imprensa Acadêmica (1864)\n",
      "miscelanea/mams05.txt: Pedro Luís (1884)\n",
      "miscelanea/mams06.txt: A morte de Francisco Otaviano (1889)\n",
      "miscelanea/mams07.txt: Secretaria de Agricultura (1890)\n",
      "miscelanea/mams08.txt: A Paixão de Jesus (1904)\n",
      "miscelanea/mams09.txt: Gonçalves Dias (1906)\n",
      "miscelanea/mams10.txt: A Estátua de José de Alencar (1906)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(machado.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objetivo para exemplificar é comparar o uso de advérbios entre várias obras.\n",
    "# É necessário realizar a etiquetagem morfossintática (pos-tagging) de cada palavra dos contos e crônicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes do etiquetador morfossintático do spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\mflav\\anaconda3\\lib\\site-packages (23.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mflav\\anaconda3\\lib\\site-packages (68.2.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\mflav\\anaconda3\\lib\\site-packages (0.41.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in c:\\users\\mflav\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (1.25.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/usage\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U spacy\n",
    "# Abrir o prompt pelo Anaconda e executar\n",
    "#python -m spacy download en_core_web_sm\n",
    "#python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Será', 'VERB'), ('que', 'SCONJ'), ('vai', 'AUX'), ('funcionar', 'VERB'), ('essa', 'DET'), ('etiquetagem', 'NOUN'), ('?', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "doc = nlp('Será que vai funcionar essa etiquetagem?')\n",
    "etiq = [(X.orth_, X.pos_) for X in doc]\n",
    "print(etiq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romance/marm01.txt\n",
      "romance/marm02.txt\n",
      "romance/marm03.txt\n",
      "romance/marm04.txt\n",
      "romance/marm05.txt\n",
      "cronica/macr01.txt\n",
      "cronica/macr02.txt\n",
      "cronica/macr03.txt\n",
      "cronica/macr04.txt\n",
      "cronica/macr05.txt\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat \n",
    "\n",
    "obras = list()\n",
    "\n",
    "for i in range(1,6):\n",
    "    obras.append('romance/marm0'+str(i)+'.txt')\n",
    "\n",
    "for i in range(1,6):\n",
    "    obras.append('cronica/macr0'+str(i)+'.txt')\n",
    "\n",
    "cont_adv = list()\n",
    "\n",
    "for obra in obras:\n",
    "    print(obra)\n",
    "    s = machado.raw(obra)\n",
    "    doc = nlp(s)\n",
    "    etiq = [(pal.orth_, pal.pos_) for pal in doc]\n",
    "    adv = [(ort, pos) for (ort, pos) in etiq if pos == 'ADV']\n",
    "    cont_adv.append(len(adv) / len(etiq))\n",
    "\n",
    "rom_m = stat.mean(cont_adv[:4])\n",
    "rom_dp = stat.stdev(cont_adv[:4])\n",
    "cro_m = stat.mean(cont_adv[:5])\n",
    "cro_dp = stat.stdev(cont_adv[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romance \t 0.059228932420173935\n",
      "Romance \t 0.0034634010945340512\n",
      "Cronicas \t 0.05884309279220977\n",
      "Cronicas \t 0.0031210128882707875\n"
     ]
    }
   ],
   "source": [
    "print('Romance \\t',rom_m)\n",
    "print('Romance \\t',rom_dp)\n",
    "print('Cronicas \\t',cro_m)\n",
    "print('Cronicas \\t',cro_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/da/88/513a104dc2b3e9c1395598480466c55d2b1358e05c7198764670c4b1ddd0/matplotlib-3.7.3-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.7.3-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/94/0a/5eb57dd395fade977786b2d2c98c2bee8234358794be44422fe58a719d42/contourpy-1.1.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/1c/c6/408ee90eae2fd7ef85c5baaedfc8d533805f4c54fc6670dbde9539f1277b/fonttools-4.42.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading fonttools-4.42.1-cp310-cp310-win_amd64.whl.metadata (154 kB)\n",
      "     ---------------------------------------- 0.0/154.1 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 112.6/154.1 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 154.1/154.1 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/4a/a1/8a9c9be45c642fa12954855d8b3a02d9fd8551165a558835a19508fec2e6/kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from matplotlib) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mflav\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.7.3-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/7.5 MB 4.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/7.5 MB 4.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.8/7.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.1/7.5 MB 6.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.5/7.5 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.7/7.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.4/7.5 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.9/7.5 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.3/7.5 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.8/7.5 MB 7.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.2/7.5 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.7/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.0/7.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.5/7.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.1/7.5 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.1.0-cp310-cp310-win_amd64.whl (470 kB)\n",
      "   ---------------------------------------- 0.0/470.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 470.4/470.4 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading fonttools-4.42.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.4/2.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB ? eta 0:00:00\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.1/103.1 kB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.42.1 kiwisolver-1.4.5 matplotlib-3.7.3 pyparsing-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_obra = ('Romances', 'Crônicas')\n",
    "x = [0,1]\n",
    "y = [rom_m, cro_m]\n",
    "dp = [rom_dp, cro_dp]\n",
    "\n",
    "plt.bar(x, y, yerr = dp)\n",
    "plt.xticks(x, tipo_obra)\n",
    "plt.ylabel('Percentual médio de advérbios (%)')\n",
    "plt.title('Adverbiação média em obras de M. de Assis')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3768297091b44acbe473c5b73c7cead172651c8d7375651eef94c19d1bc8b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
